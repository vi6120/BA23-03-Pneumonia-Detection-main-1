%%%
%
% $Autor: Wings $
% $Datum: 2021-05-14 $
% $Dateiname: 
% $Version: 4620 $
%
% !TeX spellcheck = GB
% !TeX program = pdflatex
% !TeX encoding = utf8
%
%%%



\chapter{Machine learning: Neural networks generate content}

Generative Adversarial Networks are neural networks that generate texts, videos or music. They are good for restoring old films, but also for falsifying them.

If you take a quick look at the landscape picture in the first image, nothing in
particular strikes you at first. The photo could have been taken anywhere in Germany. A look at the details, such as the tree trunks or the incidence of light, creates the feeling that something is not right here. 

The solution: this landscape does not exist. The picture was generated by a programme (GauGAN). This was made possible by an idea Ian Goodfellow had in 2014. He went to a pub with a colleague and both discussed one of the biggest challenges in Deep Learning: the amount of examples a neural network needs to learn. Image recognition requires thousands of images. A human being has to look at these beforehand and describe what can be seen on them (labelling) so that the learning process later knows whether the result of the neural network is correct or incorrect.

Ian Goodfellow's colleague didn't want to "merely" analyse image content, but to generate completely new images. After a long discussion, Ian Goodfellow came up with a question: If it doesn't work with one neural network and a lot of prepared data, why not try it with two neural networks? These then compete against each other like in a game. One network generates the images and the second judges whether they are real or generated. Through the learning process, each of the networks becomes better and better at it's respective activity without needing any data with descriptions (labels).


\begin{figure}
	\includegraphics[width=\textwidth]{GAN/GAN01}
	\caption{Where can this landscape be found? In Germany? Or in France?} 
	\label{GAN01}
\end{figure}


\begin{itemize}
	\item In Generative Adversarial Networks (GAN), neural network learns from each other as counter-players and improve their skills through constant competition. The goal of their game is a generator network that can artificially create content.
	\item With the help of GANs, you can do a lot of useful things such as restoring old films, but you can also distort content just as well, keyword deepfake.
	\item Ian Goodfellow's classic GAN architecture has laid the foundation for a number of further developments, including DCGAN Deep Convolutional GAN, PGGAN Progressive Growing GAN or CGAN Conditional GAN.
\end{itemize}

Ian Goodfellow tried this approach on a simple example and achieved the hoped-for results. The later publication \HREF{https://arxiv.org/pdf/1406.2661.pdf}{ "Generative Adversarial Nets"  (PDF)} founded a new branch of machine learning. The following two figures demonstrate the possibilities.


\begin{figure}
	\includegraphics[width=\textwidth]{GAN/GAN02}
	\caption{NVIDIA's StyleGAN project generate images of non-existent people.} 
	\label{GAN02}
\end{figure}


"Generative" here describes the possibility of generating new things with these nets. The second term, "adversarial", can best be translated in German as "kontroversial" or "gegnerisch". Two neural networks compete against each other and learn from it - learning through rivalry.

\begin{figure}
	\includegraphics[width=\textwidth]{GAN/GAN03}
	\caption{University of Berkeley's CycleGAN transfers image style to new images} 
	\label{GAN03}
\end{figure}


The examples in this article refer to the generation of images, as this is the easiest place to publish them. However, GANs can just as well generate texts, sounds, videos or other digital data. This applies to anything that can be represented in digital data.

\section{Create something new}

When it comes to creating new content, not just anything should be generated, but there is always a specific requirement, such as creating landscape images. For this, the "first ingredient" is as many landscape images as possible. From these, the chosen machine learning method can acquire the pattern that is hidden in the images. This hidden pattern is what makes up this type of image. From a mathematical point of view, this is the common, unknown probability distribution regarding the authenticity of the images. A newly generated image should preferably have this distribution in order to pass again as a landscape image. To ensure that it is not a copy of an already existing image, the "second ingredient" is a set of random numbers as input.

In GANs, there are two neural networks. One is the generator, which generates new images, and the other is the discriminator, which judges how good the new image is. You can compare this to an art forger who tries to paint the best possible pictures in the style of a Van Gogh. The police art expert is his counterpart, who has the task of distinguishing the forged paintings from genuine works that may not yet be known. If the expert recognises a forged painting, it means that the forger was not good enough. The forger still has to learn. If the forger (generator) gets better and better, the expert (discriminator) may no longer recognise a forgery. Then the expert (discriminator) has to learn again.

During the learning process, the two networks continue to grow. They virtually build each other up, just as rivals in sport do, for example. At the end of the learning process, there is a generator network that can be used to create very good new, non-real images.

\section{Mutual performance monitoring}

Like all neural networks that are supposed to get better and better through learning processes, both the generator and the discriminator need a function that tells them how good or bad they currently are. In GANs, there is not only one loss function, but each of the networks has its own. Basically, the learning process goes like this: The generator (G) gets a set of random numbers (vector z) as input and generates new images (xg) from them. The discriminator (D) in turn receives these (xg) as input and also real images (xe). Its task is to recognise the difference.

\begin{figure}
	\includegraphics[width=\textwidth]{GAN/GAN04}
	\caption{The loss functions control the learning of the neural networks in GANs.} 
	\label{GAN04}
\end{figure}


Distinguishing between two things is a classic task for neural networks. Is the picture a car or a ship? The technical term for this is binary classifier (Binary Classifier).

The result of the discriminator D(x) is 1 if it is a genuine image and 0 if it detects a generated one. A value of 0.7 would express that it is more likely to be a genuine work. The discriminator would be 70 per cent certain. The result of the discriminator D(x) thus corresponds to the assessment of whether it could be a genuine image.

The loss function for the discriminator is composed of the sum D(xe) for the real images and the sum (1 -D(xg)) for the generated images or the sum (1-D(G(x))) if xg is replaced by D(G(x)). In somewhat more mathematical terms, this looks like Ian Goodfellow's figure below.

\begin{figure}
	\includegraphics[width=\textwidth]{GAN/GAN05}
	\caption{The mathematical representation of a loss function consists of two sums.} 
	\label{GAN05}
\end{figure}

J(D) is the loss function of the discriminator and J(G) with a minus in front of it is that of the generator. This represents the opposite intentions of the generator and discriminator.

A simple neural network corresponds to an optimisation problem in which the learning process changes its parameters until the best values, i.e. the smallest possible value for the loss function, emerge as the result. This is different with GANs.

It is a game between two participants. If one participant gets better scores, the other automatically gets worse. If one player improves by a certain amount, the other gets worse by the same amount. The sum of the values achieved always remains the same. In game theory, this is known as a zero-sum game.

The aim of the learning process is to reach the situation where the images generated by the generator correspond to the internal pattern of the real images. Then the discriminator can no longer distinguish between "generated" and "real", so the result it gives is always 50 per cent (D(x) = 0.5).

At the end of the learning process, the parameters of the generator are set so that its loss function J(G) has reached a local minimum, and for the discriminator this is also true for its loss function J(D).

\section{Training in rotation}

The training of a GAN is somewhat different from that of a simple neural network. In a learning loop, the discriminator is trained first and then the generator. In the next run, it starts all over again


\begin{figure}
	\includegraphics[width=\textwidth]{GAN/GAN06}
	\caption{GANs involve two networks competing against each other, unlike simpler neural networks} 
	\label{GAN06}
\end{figure}

In the same way, the training procedure differs in detail for each neural network.



\section{Training of the discriminator}

\begin{itemize}
	\item Select random images from the real sample data.
	\item Give the generator random data from which it generates images.
	\item Classify all images whether they are real or generated, regardless of where they come from.
	\item Adjust your parameters via the loss function using the backpropagation method. The aim is to minimise the error rate when classifying.
\end{itemize}


\section{Training the generator}

\begin{itemize}
	\item Take random data and generate new images from it.
	\item Let the discriminator classify them.
	\item Adjust your parameters via the loss function using the backpropagation method. The goal is to maximise the error rate when classifying.
\end{itemize}

\medskip


The important thing here is that each neural network only adjusts its own parameters during a learning process.

\section{From theory to practice}

The GAN in the example programme gan.py from the listing tries to create handwritten digits that look as realistic as possible.

\begin{figure}
	\includegraphics[width=\textwidth]{GAN/GAN07}
	\caption{Python GAN learns to generate handwritten digits} 
	\label{GAN07}
\end{figure}

The real images come from \HREF{https://minsuk.com/research/papers/kahng-ganlab-vast2018.pdf}{ Professor Yann LeCun and his colleagues in the Artificial Intelligence Department (PDF) }  at New York University.

\begin{code}
	\lstinputlisting[language=Python]{../Code/General/GAN/gan.py}
	\caption{File \FILE{gan.py}} \label{code:gan}    
\end{code}    


Known as MNIST (Modified National Institute of Standards and Technology) in the field of machine learning, this image database was created from 60000 digits, written by employees of the American Census Bureau and another 10,000 examples of American high school students. Normally, ML uses these images to generate networks that can distinguish digits in GANs to generate realistic ones.

The Python example programme works with Keras and the TensorFlow-2-API.  \HREF{https://torres.ai/generative-adversarial-networks/}{The free programme collection by Erik Linder-Norén serves as a model.}. There you can find the implementations of various further developments of the classic GAN in Python.

All Keras modules and objects can be found at tensorflow.keras. The MNIST images needed for learning can also be imported from there. The output of the programme is prepared in the  \PYTHON{statistics} module.

Each image in MNIST consists of 28 by 28 pixels and different grey levels. The number of random numbers (vector z) that the generator receives as input is 100 in this example: \PYTHON{Z\_DIM = 100}.

\section{The game structure}

The generator (see function \PYTHON{build\_generator}) consists of several layers of the type  \PYTHON{Dense}. All neurons are connected to each other. \PYTHON{LeakyReLU} is used as the activation function between the layers.

The normal function  \PYTHON{ReLU} sets all values that are smaller than 0 to the value 0. The activation function \PYTHON{LeakyReLU}, on the other hand, returns a negative value that is slightly smaller than 0, such as 0.01 * x, for such values (x). This often allows the optimiser to reach the goal more quickly.

The last layer has \PYTHON{tanh} as an activation function so that the values for the output of the generator are between -1 and 1.

Like the generator, the discriminator (see function \PYTHON{build\_discriminator}) consists of layers of the type \PYTHON{Dense}and also works with the activation function  \PYTHON{LeakyReLU}. The last layer of the network has \PYTHON{sigmoid} as its activation function so that the output of the discriminator is between 0 and 1. The output in this case corresponds to the probability that the discriminator generates the image for
(0) or genuine (1).

The model for training the discriminator is composed of the neural network of the discriminator, an Adam optimiser and the loss function binary cross entropy. This describes the difference between probability distributions, in this case between the value estimated by the discriminator and the actual value (0 = generated, 1 = real).

The article "A Gentle Introduction to Generative Adversarial Network Loss Functions" by Jason Brownlee describes in detail why the cross entropy can be used for GANs and \HREF{https://www.iangoodfellow.com/slides/2019-05-07.pdf}{"Classical formula"(PDF)} by Ian Goodfellow cannot be used directly. For the learning process of the generator, one needs a combination of the neural network of the generator and the discriminator. Since only the generator is supposed to learn in this model, the  \PYTHON{trainable}setting of the discriminator is set to  \PYTHON{False} .

\section{Improve step by step}

The learning process runs in the \PYTHON{train} function. With each loop pass, the discriminator learns first and then the generator. For the discriminator, the \PYTHON{train} function first selects random images from the real ones. After that, it needs a corresponding number of generated images from the generator.

The Keras function \PYTHON{train\_on\_batches} gets the images as the first parameter and the corresponding labels as the second. When training with the real images \PYTHON{imgs} the vector \PYTHON{valid} for the labels consists of ones. The one here means "real", the zero "generated". The return value \PYTHON{d\_loss\_real} is a vector that contains the loss value of the discriminator's estimation for each image.

When training with the generated images \PYTHON{gen\_imgs} and the vector \PYTHON{gen} with the labels (contains only 0), the vector \PYTHON{d\_loss\_fake} provides the loss values for the generated images. The total loss value can be determined from the values \PYTHON{d\_loss\_real} and \PYTHON{d\_loss\_gen} with a weighting of 0.5.

In the learning process of the generator, the model combined, consisting of the networks of the generator and discriminator, is used. In the \PYTHON{train\_on\_batch} function, the generator first receives the input \PYTHON{noise} (random values) and thus generates an image. This is immediately passed on to the discriminator, which evaluates it. However, this function only trains the generator, as the training for the discriminator is switched off in the model \PYTHON{combined}.

Both neural networks have gone through their learning process and the loop starts again from the beginning. When the entire learning process is complete, the generator takes over creating the new images on its own.

Ian Goodfellow's classic GAN described here triggered an avalanche of further developments.

\section{GAN-Zoo}

The idea of the GAN architecture by Ian Goodfollow in 2014 was the starting signal for many further developments.

\begin{itemize}
	\item \textbf{DCGAN Deep Convolutional GAN:} The DCGAN replaces the classic fully linked layers (dense) with the convolutional layers known from Deep Learning. These are more powerful for image recognition and similar topics. Fewer learning processes are necessary. In addition, data is normalised between the individual layers (batch normalisation), which further improves performance.
	\item \textbf{PGGAN Progressive Growing GAN:} The essential new feature of PGGAN is the learning process. This becomes increasingly difficult the more the neural networks swell. In order to achieve better resolutions for images or other data, however, the networks have to keep growing. The idea behind PGGAN is to start with the smallest possible networks in the generator and discriminator. First you take images with low resolution, together with a few layers, and increase this more and more. This shortens the time for the learning process. This allows PGGANs to achieve higher resolutions in images with the same resources.
	\item \textbf{Cycle GAN:} CycleGAN is about automatically transferring images from one domain, such as summer images, to another domain, winter images. Until now, pairs of images were always necessary for the learning process, a winter image and a corresponding summer image. Of course, it is very time- consuming to first obtain as many of these image pairs as possible. CycleGAN manages this transfer from one image to another without image pairs. This makes it possible, for example, to convert photos into pictures of famous painters. There can be no image pairs for this.
	\item \textbf{CGAN – Conditional GAN}: CGAN do not generate just any images, the user controls how they should look. If there is additional data (features) about the gender, age or appearance of the person depicted, he or she can wish the generated image to show, for example, a red-haired, 20-year-old man.
\end{itemize}


If the user can determine the appearance of the image via specifications, the perspective for the future is that such GANs could one day be able to replace the classic graphics engines, for example in computer games.

A list of many more GANs can be found on Avinash Hindupur's GAN Zoo page.

\section{Real or computer generated?}

Since 2017, the term deepfake has been doing the rounds. This stands for images or other computer-generated media that look deceptively real.

For example, if a person is to have a particularly positive effect on a social platform, he or she needs as many followers as possible - why not create many fake accounts that follow you? This in turn requires pictures of people. Anyone who has read this article about GANs will know where to get them. According to a report by heise online, researchers have already identified countless fake accounts on Facebook.

Of course, much more is possible with neural networks. For example, there are generated videos in which Barack Obama says what the "scriptwriters" have come up with. In the same way, programmes can imitate a person's biometric data or put faces of celebrities on the bodies of porn stars. 

In order to be able to do something about this, it is currently up to the lawyers and the technicians. Legislation must be updated to make such offences punishable. For example, the US House of Representatives is preparing an anti-deepfake bill.

On the technology side, one of the goals is the automatic detection of deepfakes. Facebook has offered rewards totalling 10 million US dollars in its Deepfakes Detection Challenge. As is often the case in the field of IT security, there will probably be a constant neck-and-neck race between the producers of deepfakes and those who expose them.

But GANs and similar technology offer just as many positive applications, from simpler workflows for post-processing images and films to the automatic restoration of photos. Neural network techniques even have the potential to replace existing graphics engines and generate ever better images and sounds in films and computer games.



\chapter{Package \PYTHON{Example}}

\index{Example}

\section{Introduction}

\index{Example!Introduction}


\section{Description}

\index{Example!Description}

\section{Installation}

\index{Example!Installation}

\SHELL{pip packageExample}

\section{Example - Manual}

\section{Example}

\section{Example - Version}

\section{Example - Files}

\FILE{PackageExample.py}



\section{Further Reading}

\nocite{Abadi:2016}

	% Überschrift ein Level unter `refsection=chapter`, also \section*:
   \printbibliography[heading=subbibliography, segment=\therefsegment]










